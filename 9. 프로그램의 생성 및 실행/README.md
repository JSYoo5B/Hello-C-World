# 프로그램의 생성 및 실행

이 전 챕터들을 학습하며 간단한 C 프로그램을 작성하는 것에는 어느정도 익숙해졌을 것이다. 그런데 변수나 함수 등 챕터에서 설명들을 보면 메모리가 어쩌느니 영역이 어쩌느니 하는 설명들이 등장하며 혼란을 초래했을 것이다. 내용을 어렵게 만들어 독자분들을 골탕먹이려는 속셈이 아니냐 생각할 수 있겠지만, 동작 원리와 같은 것들을 명확하게 설명하기 위해서는 필수불가결한 내용들이었다.  
여태까지는 중간에 컴퓨터나 프로그램의 동작 원리와 같은 내용을 추가하여 설명 돌려막기를 시전하였지만 이후 내용부터는 이러한 설명 방식에 한계가 있을 것으로 보인다. C언어는 운영체제를 만들기 위해 탄생한 언어인 만큼 컴퓨터를 제어하기 위한 막강한 기능들이 포함되어 있다. 이러한 기능들을 명확히 이해하기 위해서는 컴퓨터 아키텍처와 프로그램 동작 방식에 대한 이해가 필요하다.  
따라서 해당 챕터에서는 추후 내용을 원활하게 이해할 수 있도록 컴퓨터 및 프로그램에 대한 설명을 진행할 것이다. 물론 이러한 내용들을 상세하게 설명하면 그 자체로 여러 권의 책을 집필할 수 있을 분량이고 학습에도 부담이 있을 것이므로 되도록 최소 한도의 내용만 진행할 것이다.  
이 외에도 추후 학습에 도움이 될 컴파일러와 디버거 사용법들도 어느 정도 소개할 것인데, 너무 부담 가질 필요는 없다. 일단은 이러한 내용도 있다고 적당히 알아두고 필요할 때마다 해당 챕터를 돌아보거나 검색하면서 진행하여도 충분하다.  

## 컴퓨터 구조 찍어먹기

기본적으로 컴퓨터는 CPU를 중심으로 여러 장치들이 모여서 구성된다. 목적과 환경에 따라 구성이 크게 달라지기에 우선 일반적인 데스크탑 환경을 가정하면 다음과 같은 요소들이 포함된다.  

* CPU(Central Processing Unit) : 중앙 처리 장치는 명령어를 수행하여 컴퓨터 시스템을 제어하는 가장 핵심적인 장치이다. 일반적으로 ALU, 제어 장치, 레지스터와 같은 요소로 구성된다. 이러한 기본적인 요소들을 모듈화하여 만든 칩을 마이크로프로세서(microprocessor)라고도 하며, 마이크로프로세서에 입출력 모듈과 같은 외부 제어 요소들을 통합하여 만든 칩을 마이크로컨트롤러(microcontroller)라고도 한다.  
    * ALU(Arithmetic and Logic Unit) : 산술 연산, 논리 연산 등을 담당하는 연산 장치이다.
    * 제어 장치(Control Unit) : 주로 명령어를 읽고 해석하며 데이터 처리를 위한 기능들을 제어하기 위한 장치이다.
    * 레지스터(Register) : 프로세서 내에서 자료를 보관하고 처리하기 위한 아주 빠른 기억 장소이다. 크게 범용 레지스터와 특수 레지스터로 구분한다.
        * 범용 레지스터 : 범용적인 데이터 처리를 위하여 데이터 및 주소를 저장한다.
        * 특수 레지스터 : 특수한 기능을 위해 용도가 정해져 특정한 데이터 및 주소를 저장한다.
* 캐시 메모리 : 데이터를 미리 복사해둔 임시 저장소로 데이터 요청이 발생했을 때 빠르게 응답하기 위하여 사용한다. 캐시는 다양한 하드웨어 및 소프트웨어의 구성 요소로 사용된다. 예를 들어 메인 메모리에 있는 데이터를 CPU에게 빠르게 전달하기 위한 캐시를 CPU 캐시라고 하며, 디스크에 있는 데이터를 빠르게 메모리 등 외부로 전달하거나 디스크 쓰기 요청을 빠르게 수행하기 위한 캐시를 디스크 캐시라고 한다.
* RAM(Random Access Memory) 메모리 : 임의의 영역에 접근하여 읽고 쓰기가 가능한 주기억장치(메인메모리)로, 일반적으로 전력이 공급되지 않으면 데이터가 사라지는 휘발성 메모리이다. 어느 위치에 접근하든지 동일한 시간이 걸리기 때문에 랜덤 액세스 메모리라고 부른다.
* HDD/SSD : 전력이 공급되지 않아도 데이터가 휘발되지 않는 비휘발성 메모리로 보조 기억 장치로 사용한다.
    * HDD(Hard Disk Drive) : 플래터를 회전하여 자기 패턴으로 정보를 기록하는 메모리로, 데이터가 저장된 위치에 따라 접근 시간이 달라진다.
    * SSD(Solid State Drive) : 일반적으로 플래시 메모리를 사용하여 전자식으로 정보를 기록하는 메모리로, 데이터가 저장된 위치에 따른 접근 시간이 HDD에 비해 상대적으로 균일하다.
* GPU(Graphics Processing Unit) : 그래픽 연산을 빠르게 처리하여 결과 값을 모니터에 출력하기 위한 연산 장치이다. CPU와 비교하여 굉장히 많은 수의 연산 장치가 간단한 구조로 내장되어 있기 때문에 처리할 데이터가 많은 연산을 수행하기에 적합하다.
* 메인보드(Mainboard/Motherboard) : 컴퓨터 시스템의 구성 요소들을 장착할 수 있는 슬롯을 제공하며 해당 요소들에 전원을 공급하고 요소들간에 신호를 주고받는 통로인 버스를 제공하는 전자기판이다.
    * 버스(bus) : 컴퓨터 시스템의 구성 요소들 간에 데이터와 정보를 전송하기 위한 통로이다.

일반적으로 프로그램은 외부 저장 장치에 저장되어 있다가 실행되면 주기억장치인 RAM에 로드된다. 주기억장치로 올라온 프로그램의 명령어와 데이터들은 버스를 통해 CPU로 이동하여 명령을 수행한다. 이렇게 범용적인 하드웨어 구조에 프로그램을 내장시키고 메모리로부터 명령어와 데이터를 CPU로 가져오는 구조를 폰 노이만 아키텍처(Von Neumann Architecture)라고 한다.  

그런데 컴퓨터가 발전할수록 CPU의 연산 속도는 굉장히 빠르게 증가했지만 메모리 접근 속도는 상대적으로 느리게 증가했다. 이러한 불균형으로 생기는 병목 현상은 폰 노이만 아키텍처의 고질적인 문제인데, 이를 해소하기 위하여 CPU 내에 캐시 메모리를 두었으며 현재 많은 경우 세 단계의 캐시 메모리를 사용하고 있다.  

> 실제 캐시 메모리가 적용된 컴퓨터 시스템은 1950년대에서 1960년대에 등장하였는데, 폰 노이만은 1946년 그의 논문에서 이미 캐시 메모리의 필요성에 대해 예견하였다.  

그리고 CPU의 연산 속도 또한 증가하다보니 과도한 에너지 소모와 발열량으로 인하여 어느 정도 한계를 맞이하였다. 이러한 한계를 극복하기 위하여 다수의 연산 처리 장치 모듈을 하나의 칩에 내장한 멀티 코어 CPU가 등장하였다. 연산 처리 장치 모듈을 코어라고 하며, 각 코어는 독자적이고 병렬적으로 명령어를 수행할 수 있다.  

다시 캐시 이야기로 돌아와서 세 단계의 CPU 캐시 메모리가 구성된다고 했을 때, CPU와 가장 가깝고 가장 빠르게 접근할 수 있는 캐시를 L1 캐시라고 하며, CPU로부터 가장 멀리 있는 캐시를 L3 캐시라고 한다. 이 경우 CPU는 메모리에 접근할 때 RAM에 직접 접근하지 않고 항상 캐시 메모리로 접근한다. CPU가 원하는 데이터 혹은 명령어가 L1 캐시에 있으면 바로 불러오고, 없다면 L2 캐시로부터 L1 캐시로 불러온 후 L1 캐시로부터 불러온다. L2 캐시에도 데이터가 없다면 L3 캐시로부터 L2 캐시로 불러오고, L3 캐시에도 데이터가 없다면 RAM에서 L3 캐시로 불러오는 방식이다. 일반적으로 L1 캐시와 L2 캐시는 CPU 코어마다 존재하고, L3 캐시는 CPU 코어들이 공유하여 사용한다.  

위에 CPU의 처리 속도와 메모리 접근 속도의 차이로 인한 병목 현상을 이야기 했는데, 폰 노이만 아키텍처의 유사한 고질적인 문제로 데이터와 명령어에 동시에 접근할 수 없다는 점이 있다. 고전적인 폰 노이만 아키텍처에서는 데이터 메모리와 명령어 메모리가 구분되어 있지 않고 같은 버스를 통해 CPU로 이동하기 때문에 데이터와 명령어를 병렬적으로 가져올 수 없다. 이러한 구조는 다음 명령어를 가져오거나 실행하려는 명령어에서 필요한 데이터를 가져오는데에 약점을 갖는다.  
이를 극복하기 위하여 명령어를 위한 버스와 데이터를 위한 버스를 물리적으로 분리한 구조를 하버드 아키텍처(Harvard Architecture)라고 한다. 하버드 아키텍처에서는 실행하려는 명령어를 끊기지 않고 가져올 수 있으므로 더 빠르게 명령어를 처리할 수 있다. 하지만 완전한 하버드 아키텍처를 구현하기 위해서는 많은 회로와 메모리 분리가 필요하며 이로 인해 비용과 복잡성이 늘어난다. 그 외에도 하드웨어의 명령어 처리 과정에 있어 일부 제한들이 생길 수 있다.  

현대의 많은 CPU는 폰 노이만 아키텍처와 하버드 아키텍처를 절충하여 복잡성과 속도 문제에 적절히 대처하고 있다. L1 캐시는 데이터 캐시와 명령어 캐시로 나누고 코어 모듈에 전용 버스로 연결한다. 이에 반해 L3 캐시와 주기억장치는 데이터와 명령어를 위한 영역을 따로 나누지 않고 같은 버스를 통해 통신한다. 이 외에도 컴퓨터 시스템의 전반적인 성능을 증가시킬 방법이 있다면 적용하며 구조를 개선하고 있다.  

### 메모리 계층 구조

메모리 계층 구조(Memory Hierarchy)는 메모리의 종류를 속도, 용량, 성질 등에 의해 구분하여 필요에 따라 나누어 두는 것을 뜻한다. 일반적으로 다음과 같은 그림으로 나타내는데, 표현하고자 하는 바에 따라 구분 방식이 조금씩 달라서 내용은 조금씩 다를 수도 있다.  
![memory_hierarchy]()  

메모리는 하드웨어적인 구현 방법, 크기, CPU와의 물리적인 거리에 따라 접근 시간이 달라진다. 예를 들어 RAM도 기억 장치를 어떻게 구성하는지에 따라 동작 방식이 달라져서 SRAM(Static Random Access Memory)와 DRAM(Dynamic Random Access Memory)로 나뉜다. SRAM은 접근 속도가 빠르지만 대용량으로 만들기 어렵고 많은 비용이 든다. DRAM은 상대적으로 접근 속도가 느리지만 비교적으로 대용량으로 만들기 쉽고 적은 비용이 든다. 따라서 일반적으로 CPU 캐시 메모리는 SRAM으로, 주기억장치는 DRAM으로 제작한다. (집필 중인 현재 많은 CPU 캐시는 SRAM으로, 주기억장치를 보통 DRAM의 일종인 SDRAM으로 제작하고 있다. 물론 모두 그런 것은 아니다.) 그리고 같은 기억 소자를 사용한다고 하더라도 크기가 작을수록 접근 속도를 빠르게 만들기 쉽다. 예를 들어 동네 놀이터 작은 모래 사장에 떨어진 500원을 찾는 것과 드넓은 사막에 떨어진 500원을 찾는다고 할 때 어느 쪽이 빠르게 찾기 쉬운지 생각하면 이해하기 쉽다. 따라서 일반적으로 속도에 최적화된 설계를 한 SRAM을 L1 캐시로 사용하고, 크기에 최적화된 설계를 한 SRAM을 L2와 L3 캐시에 사용하고는 한다.  

정리하면 CPU와 가까이 있을 수록 빠르지만 용량이 적고, CPU에 멀리 있을 수록 느리지만 용량이 큰 기억 장치를 사용하고 있다. 이러한 상황에서 메모리를 효율적으로 사용하려면 어떻게 해야할까? 당연하지만 CPU가 미래에 자주 사용할 데이터일수록 빠른 메모리에 위치해두는 것이 좋다.  
그러면 어떤 데이터가 미래에 자주 사용할지 어떻게 알 수 있을까? 완벽한 예측을 할 수는 없지만 힌트가 될 만한 두 가지 규칙이 있다. '한 번 접근한 데이터는 미래에 다시 접근할 확률이 높다' 와 '방금 접근한 데이터 주변에 있는 데이터에 접근할 확률이 높다' 이다. 예를 들어 ```for (int i = 0; i < 100; i++) { sum += i; }``` 와 같은 문장이 있으면 변수 i에 자주 접근하는 것을 생각해보면 된다. 이러한 성질을 지역성(Locality) 라고 하는데 특히 전자 규칙을 시간적 지역성(Temporal Locality)라고 하며 후자 규칙을 공간적 지역성(Spatial Locality)라고 한다.  
지역성에 의거하여 어떠한 데이터를 필요할 때 인근 주소의 데이터들과 함께 상위 캐시 메모리로 복사되도록 만들면 속도와 공간 효율을 적당히 잡을 수 있다. 이런 식으로 데이터들을 캐시 메모리에 동적으로 복사해두고, CPU가 해당 데이터에 접근할 때 캐시 메모리에 존재하면 캐시 히트(Cache Hit)라고 하고 존재하지 않으면 캐시 미스(Cache Miss)라고 한다. 캐시 미스가 발생하면 하위 메모리에서 데이터를 찾아서 인근 데이터들과 함께 상위 메모리로 복사하는 작업을 반복하며 메모리가 동작한다.  

## 프로그램의 생성 과정

## 프로그램의 실행 과정

## 컴파일러와 디버거